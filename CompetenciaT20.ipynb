{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3875fe7",
   "metadata": {},
   "source": [
    "# Version - Versi√≥n Light\n",
    "Sin documentaci√≥n solo referencia ajustar y realizar pruebas.\n",
    "Archivo para entrenar y validar contiene en total 222 ejemplos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603361ca",
   "metadata": {},
   "source": [
    "# Librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0aa6d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import math\n",
    "from typing import Any, Dict, List\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import evaluation_metric as custom_metrics\n",
    "import torch.utils.checkpoint\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    get_scheduler\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from transformers import logging as hf_logging\n",
    "hf_logging.set_verbosity_warning()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84dc899",
   "metadata": {},
   "source": [
    "# Variables globales y funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0975cc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Directorios\n",
    "DATA_PATH = \"data/smalltrain/natural_purchase_order_6.json\" # por ahora tomo este ejemplo light de 222 registros\n",
    "OUTPUT_DIR = \"output/qwen_04\"\n",
    "EXPECTED_JSON_FILE = \"data/template/expected_output.json\"\n",
    "EXPECTED_JSON = None\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Modelo\n",
    "MODEL_NAME = \"Qwen/Qwen3-0.6B-Base\"\n",
    "# Data\n",
    "TEST_SIZE = 0.2\n",
    "# Tokenizaci√≥n\n",
    "MAX_LENGTH = 1024\n",
    "# Dataloader\n",
    "BATCH_SIZE = 1\n",
    "# Entrenamiento\n",
    "GRAD_ACCUM_STEPS = 4\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 2e-4\n",
    "WEIGHT_DECAY = 0.01\n",
    "WARMUP_STEPS = 10\n",
    "# Evaluaci√≥n\n",
    "NUM_VAL_EXAMPLES = 45\n",
    "# Configuraci√≥n del dispositivo\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "GLB_SEED = 42\n",
    "torch.manual_seed(GLB_SEED)\n",
    "np.random.seed(GLB_SEED)\n",
    "if DEVICE == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(GLB_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf0f147",
   "metadata": {},
   "source": [
    "# Carga de archivos y datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5c6c09",
   "metadata": {},
   "source": [
    "Cargar archivo ejemplo JSON esperado para predicci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ec62fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EXPECTED_JSON_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    EXPECTED_JSON = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3513e5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPECTED_JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f98a620",
   "metadata": {},
   "source": [
    "Cargar dataset   \n",
    "Esto es temporal mientras se ajusta el F1-Score para aquellos que estan dando cero. Temporal en cargar solo un archivo, dado que se deben cargar todos los JSON para entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d16b535b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples: 177, Val examples: 45\n"
     ]
    }
   ],
   "source": [
    "with open(DATA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_data = json.load(f)\n",
    "\n",
    "# convert to Hugging Face Dataset\n",
    "hf_dataset = Dataset.from_list(raw_data)\n",
    "\n",
    "# split train / validation\n",
    "split = hf_dataset.train_test_split(test_size=TEST_SIZE, seed=GLB_SEED)\n",
    "train_list = split['train']\n",
    "val_list = split['test']\n",
    "\n",
    "print(f\"Train examples: {len(train_list)}, Val examples: {len(val_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f7ac357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando tokenizer y modelo (esto puede tardar)...\n"
     ]
    }
   ],
   "source": [
    "print(\"Cargando tokenizer y modelo (esto puede tardar)...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# preparar para k-bit training\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# Desactivar cache y habilitar checkpointing seguro\n",
    "model.config.use_cache = False\n",
    "try:\n",
    "    model.gradient_checkpointing_enable(gradient_checkpointing_kwargs={\"use_reentrant\": False})\n",
    "except TypeError:\n",
    "    # fallback if the signature is different\n",
    "    model.gradient_checkpointing_enable()\n",
    "\n",
    "torch.utils.checkpoint.use_reentrant = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d7c7b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,293,760 || all params: 598,343,680 || trainable%: 0.3834\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae022e68",
   "metadata": {},
   "source": [
    "## Construcci√≥n del prompt para que genere el JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a21196b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(natural_text: str) -> str:\n",
    "    instructions = (\n",
    "        \"Eres un extractor de √≥rdenes. Genera SOLO un JSON v√°lido EXACTAMENTE con los campos requeridos.\\n\"\n",
    "        \"Reglas:\\n\"\n",
    "        \"- Usa null cuando un campo no exista.\\n\"\n",
    "        \"- \\\"buyer\\\" debe existir; si name/email/contact/addresses faltan, d√©jalos en null.\\n\"\n",
    "        \"- Si addresses est√° vac√≠o o no existe -> \\\"addresses\\\": null.\\n\"\n",
    "        \"- Si purchases est√° vac√≠o o no existe -> \\\"purchases\\\": null.\\n\"\n",
    "        \"- shipping es opcional; si falta -> \\\"shipping\\\": null.\\n\"\n",
    "        \"- Asegura que los tipos principales sean correctos (quantity entero, country uno de US/CA/GB/ES/CO/DE/FR).\\n\\n\"\n",
    "    )\n",
    "    prompt = instructions + \"Texto:\\n\" + natural_text + \"\\n\\nJSON:\\n\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08ef26d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_training_example(example: Dict[str, Any]) -> str:\n",
    "    natural = example['natural_language']\n",
    "    target_json = json.dumps(example['json_data'], ensure_ascii=False)\n",
    "    prompt = build_prompt(natural)\n",
    "    return prompt + target_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfbfaafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizaci√≥n (precompuesta) y construcci√≥n de datasets de tensores\n",
    "def tokenize_example_textpair(textpair: str):\n",
    "    enc = tokenizer(textpair, truncation=True, max_length=MAX_LENGTH, padding='max_length', return_tensors='pt')\n",
    "    labels = enc['input_ids'].clone()\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "    return {'input_ids': enc['input_ids'].squeeze(0), 'attention_mask': enc['attention_mask'].squeeze(0), 'labels': labels.squeeze(0)}\n",
    "\n",
    "train_tokens = [tokenize_example_textpair(build_training_example(x)) for x in train_list]\n",
    "val_tokens = [tokenize_example_textpair(build_training_example(x)) for x in val_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "861ce83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTorchDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokens_list):\n",
    "        self.data = tokens_list\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return {k: v for k, v in self.data[idx].items()}\n",
    "\n",
    "train_dataset = SimpleTorchDataset(train_tokens)\n",
    "val_dataset = SimpleTorchDataset(val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6d006de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'input_ids': torch.stack([b['input_ids'] for b in batch]),\n",
    "        'attention_mask': torch.stack([b['attention_mask'] for b in batch]),\n",
    "        'labels': torch.stack([b['labels'] for b in batch])\n",
    "    }\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "262258e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer AdamW custom + scheduler\n",
    "trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = AdamW(trainable_params, lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY, betas=(0.9,0.999), eps=1e-8)\n",
    "num_update_steps_per_epoch = math.ceil(len(train_loader) / GRAD_ACCUM_STEPS)\n",
    "max_train_steps = EPOCHS * num_update_steps_per_epoch\n",
    "scheduler = get_scheduler(name='linear', optimizer=optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps=max_train_steps)\n",
    "\n",
    "# WandB opcional\n",
    "try:\n",
    "    import wandb\n",
    "    wandb.init(project=\"qwen-json-extraction\", reinit=True)\n",
    "    use_wandb = True\n",
    "except Exception:\n",
    "    use_wandb = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6df6a0d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4577de59a032446699aa41b59d546840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 finished ‚Äî avg loss: 1.9302\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "141fdae5330e4111913e13046280cb17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 finished ‚Äî avg loss: 1.4729\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09f699d695c8455d95ee53b882b32ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/177 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 finished ‚Äî avg loss: 1.3985\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento manual con AMP (torch.amp) y tqdm\n",
    "scaler = torch.amp.GradScaler(device='cuda') if DEVICE.startswith('cuda') else torch.amp.GradScaler()\n",
    "model.to(DEVICE)\n",
    "model.train()\n",
    "\n",
    "global_step = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}\")\n",
    "    optimizer.zero_grad()\n",
    "    for step, batch in pbar:\n",
    "        input_ids = batch['input_ids'].to(DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "        labels = batch['labels'].to(DEVICE)\n",
    "\n",
    "        with torch.amp.autocast(device_type='cuda' if DEVICE.startswith('cuda') else 'cpu'):\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss / GRAD_ACCUM_STEPS\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        running_loss += loss.item() * GRAD_ACCUM_STEPS\n",
    "\n",
    "        if (step + 1) % GRAD_ACCUM_STEPS == 0 or (step + 1) == len(train_loader):\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "            global_step += 1\n",
    "\n",
    "            avg_loss = running_loss / (step + 1)\n",
    "            pbar.set_postfix({'loss': f\"{avg_loss:.4f}\", 'lr': scheduler.get_last_lr()[0]})\n",
    "            if use_wandb:\n",
    "                wandb.log({'train/loss': avg_loss, 'train/lr': scheduler.get_last_lr()[0], 'step': global_step})\n",
    "\n",
    "    print(f\"Epoch {epoch+1} finished ‚Äî avg loss: {running_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8af71aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./qwen_04\\\\tokenizer\\\\tokenizer_config.json',\n",
       " './qwen_04\\\\tokenizer\\\\special_tokens_map.json',\n",
       " './qwen_04\\\\tokenizer\\\\chat_template.jinja',\n",
       " './qwen_04\\\\tokenizer\\\\vocab.json',\n",
       " './qwen_04\\\\tokenizer\\\\merges.txt',\n",
       " './qwen_04\\\\tokenizer\\\\added_tokens.json',\n",
       " './qwen_04\\\\tokenizer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# guardar adaptador LoRA\n",
    "model.save_pretrained(os.path.join(OUTPUT_DIR, 'lora_adapter'))\n",
    "tokenizer.save_pretrained(os.path.join(OUTPUT_DIR, 'tokenizer'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac22a01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generaci√≥n robusta y normalizaci√≥n POST-PREDICCI√ìN\n",
    "def generate_json_raw(text: str, max_new_tokens: int = 256) -> str:\n",
    "    prompt = build_prompt(text)\n",
    "    enc = tokenizer(prompt, return_tensors='pt', truncation=True, padding=True, max_length=MAX_LENGTH).to(DEVICE)\n",
    "    input_ids = enc['input_ids']\n",
    "    attention_mask = enc['attention_mask']\n",
    "    pad_id = tokenizer.pad_token_id or tokenizer.eos_token_id\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,\n",
    "            pad_token_id=pad_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            use_cache=False\n",
    "        )\n",
    "    return tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "def extract_json_from_text(text: str) -> Any:\n",
    "    matches = re.findall(r\"\\{[\\s\\S]*\\}\", text)\n",
    "    if matches:\n",
    "        for m in matches:\n",
    "            candidate = m\n",
    "            candidate_fixed = candidate.replace(\"'\", '\"')\n",
    "            try:\n",
    "                return json.loads(candidate_fixed)\n",
    "            except Exception:\n",
    "                continue\n",
    "    if 'JSON:' in text:\n",
    "        part = text.split('JSON:')[-1].strip()\n",
    "        part = part.strip('`\\n ')\n",
    "        try:\n",
    "            return json.loads(part)\n",
    "        except Exception:\n",
    "            try:\n",
    "                return json.loads(part.replace(\"'\", '\"'))\n",
    "            except Exception:\n",
    "                return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32923bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_example_json_pred(js: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    # Ensure buyer exists\n",
    "    if js is None:\n",
    "        return {\n",
    "            'buyer': {'name': None, 'email': None, 'contact': None, 'addresses': None},\n",
    "            'purchases': None,\n",
    "            'shipping': None\n",
    "        }\n",
    "\n",
    "    out = {}\n",
    "    buyer = js.get('buyer') if isinstance(js, dict) else None\n",
    "    if not buyer:\n",
    "        out['buyer'] = {'name': None, 'email': None, 'contact': None, 'addresses': None}\n",
    "    else:\n",
    "        # name & email\n",
    "        out['buyer'] = {\n",
    "            'name': buyer.get('name') if buyer.get('name') is not None else None,\n",
    "            'email': buyer.get('email') if buyer.get('email') is not None else None,\n",
    "            'contact': None,\n",
    "            'addresses': None\n",
    "        }\n",
    "        contact = buyer.get('contact')\n",
    "        if contact:\n",
    "            out['buyer']['contact'] = {\n",
    "                'phone': contact.get('phone') if contact.get('phone') is not None else None,\n",
    "                'alt_email': contact.get('alt_email') if contact.get('alt_email') is not None else None,\n",
    "                'preferred_contact': contact.get('preferred_contact') if contact.get('preferred_contact') is not None else None\n",
    "            }\n",
    "        else:\n",
    "            out['buyer']['contact'] = None\n",
    "\n",
    "        addresses = buyer.get('addresses')\n",
    "        if addresses and isinstance(addresses, list) and len(addresses) > 0:\n",
    "            # keep as-is but ensure required fields exist\n",
    "            out_addrs = []\n",
    "            for a in addresses:\n",
    "                out_addrs.append({\n",
    "                    'street': a.get('street') if a.get('street') is not None else None,\n",
    "                    'city': a.get('city') if a.get('city') is not None else None,\n",
    "                    'state': a.get('state') if a.get('state') is not None else None,\n",
    "                    'postal_code': a.get('postal_code') if a.get('postal_code') is not None else None,\n",
    "                    'country': a.get('country') if a.get('country') is not None else None\n",
    "                })\n",
    "            out['buyer']['addresses'] = out_addrs\n",
    "        else:\n",
    "            out['buyer']['addresses'] = None\n",
    "\n",
    "    # purchases\n",
    "    purchases = js.get('purchases') if isinstance(js, dict) else None\n",
    "    if purchases and isinstance(purchases, list) and len(purchases) > 0:\n",
    "        out_p = []\n",
    "        for p in purchases:\n",
    "            out_p.append({\n",
    "                'product_name': p.get('product_name') if p.get('product_name') is not None else None,\n",
    "                'quantity': int(p.get('quantity')) if (p.get('quantity') is not None and str(p.get('quantity')).isdigit()) else None,\n",
    "                'currency': p.get('currency') if p.get('currency') is not None else None,\n",
    "                'discount_code': p.get('discount_code') if p.get('discount_code') is not None else None\n",
    "            })\n",
    "        out['purchases'] = out_p\n",
    "    else:\n",
    "        out['purchases'] = None\n",
    "\n",
    "    # shipping\n",
    "    shipping = js.get('shipping') if isinstance(js, dict) else None\n",
    "    if shipping:\n",
    "        out['shipping'] = {\n",
    "            'method': shipping.get('method') if shipping.get('method') is not None else None,\n",
    "            'preferred_by': shipping.get('preferred_by') if shipping.get('preferred_by') is not None else None\n",
    "        }\n",
    "    else:\n",
    "        out['shipping'] = None\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37c6439d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_VAL_EXAMPLES = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35b7f872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c181595a1bb446c0b7bb4e59b8948796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluaci√≥n:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx=0 f1=0.7560\n",
      "idx=1 f1=0.1036\n",
      "idx=2 f1=0.1515\n",
      "idx=3 f1=0.0970\n",
      "idx=4 f1=0.6542\n",
      "idx=5 f1=0.7296\n",
      "idx=6 f1=0.1194\n",
      "idx=7 f1=0.7507\n",
      "idx=8 f1=0.2282\n",
      "idx=9 f1=0.7840\n",
      "idx=10 f1=0.6747\n",
      "idx=11 f1=0.6241\n",
      "idx=12 f1=0.6892\n",
      "idx=13 f1=0.0340\n",
      "idx=14 f1=0.6106\n",
      "idx=15 f1=0.7108\n",
      "idx=16 f1=0.5680\n",
      "idx=17 f1=0.8383\n",
      "idx=18 f1=0.0388\n",
      "idx=19 f1=0.0818\n",
      "idx=20 f1=0.6293\n",
      "idx=21 f1=0.5693\n",
      "idx=22 f1=0.7289\n",
      "idx=23 f1=0.8193\n",
      "idx=24 f1=0.7632\n",
      "idx=25 f1=0.0424\n",
      "idx=26 f1=0.9587\n",
      "idx=27 f1=0.0340\n",
      "idx=28 f1=0.6164\n",
      "idx=29 f1=0.0424\n",
      "idx=30 f1=0.6178\n",
      "idx=31 f1=0.8373\n",
      "idx=32 f1=0.6854\n",
      "idx=33 f1=0.8138\n",
      "idx=34 f1=0.6371\n",
      "idx=35 f1=0.6417\n",
      "idx=36 f1=0.7110\n",
      "idx=37 f1=0.6697\n",
      "idx=38 f1=0.1036\n",
      "idx=39 f1=0.8349\n",
      "idx=40 f1=0.8209\n",
      "idx=41 f1=0.7289\n",
      "idx=42 f1=0.0941\n",
      "idx=43 f1=0.7000\n",
      "idx=44 f1=0.8193\n"
     ]
    }
   ],
   "source": [
    "# Evaluaci√≥n sobre N ejemplos con barra de progreso, CSV y gr√°fico\n",
    "results = []\n",
    "for idx, ex in enumerate(tqdm(val_list.select(range(NUM_VAL_EXAMPLES)), desc='Evaluaci√≥n')):\n",
    "    text = ex['natural_language']\n",
    "    raw = generate_json_raw(text)\n",
    "    pred_obj = extract_json_from_text(raw)\n",
    "    pred_norm = normalize_example_json_pred(pred_obj)\n",
    "    true_json = ex['json_data']\n",
    "    # evaluate_json expects a JSON string for predicted (older API) -> pass json.dumps\n",
    "    f1 = custom_metrics.evaluate_json(true_json, json.dumps(pred_norm, ensure_ascii=False))\n",
    "    results.append({'idx': idx, 'f1': f1, 'raw': raw, 'pred_norm': pred_norm, 'true': true_json})\n",
    "    print(f\"idx={idx} f1={f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e9b9b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV guardado en ./qwen_04\\validation_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Guardar CSV\n",
    "csv_path = os.path.join(OUTPUT_DIR, 'validation_results.csv')\n",
    "with open(csv_path, 'w', encoding='utf-8', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['idx','f1','raw','pred_norm','true'])\n",
    "    writer.writeheader()\n",
    "    for r in results:\n",
    "        writer.writerow({\n",
    "            'idx': r['idx'],\n",
    "            'f1': r['f1'],\n",
    "            'raw': r['raw'],\n",
    "            'pred_norm': json.dumps(r['pred_norm'], ensure_ascii=False),\n",
    "            'true': json.dumps(r['true'], ensure_ascii=False)\n",
    "        })\n",
    "print('CSV guardado en', csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6975fb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histograma guardado en ./qwen_04\\f1_distribution.png\n"
     ]
    }
   ],
   "source": [
    "# Histograma F1\n",
    "f1_scores = [r['f1'] for r in results]\n",
    "plt.figure()\n",
    "plt.hist(f1_scores, bins=10)\n",
    "plt.title('Distribuci√≥n de F1')\n",
    "plt.xlabel('F1')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'f1_distribution.png'))\n",
    "plt.close()\n",
    "print('Histograma guardado en', os.path.join(OUTPUT_DIR, 'f1_distribution.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "645ae006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Peores 3 ejemplos:\n",
      "13 0.03398058252427184\n",
      "Texto: Eres un extractor de √≥rdenes. Genera SOLO un JSON v√°lido EXACTAMENTE con los campos requeridos.\n",
      "Reglas:\n",
      "- Usa null cuando un campo no exista.\n",
      "- \"buyer\" debe existir; si name/email/contact/addresses faltan, d√©jalos en null.\n",
      "- Si addresses est√° vac√≠o o no existe -> \"addresses\": null.\n",
      "- Si purchases est√° vac√≠o o no existe -> \"purchases\": null.\n",
      "- shipping es opcional; si falta -> \"shipping\": null.\n",
      "- Asegura que los tipos principales sean correctos (quantity entero, country uno de US/CA/GB/ES/CO/DE/FR).\n",
      "\n",
      "Texto:\n",
      "# Orden de Compra de Melissa Higgins\n",
      "\n",
      "Hola! Espero que todo est√© bien por all√≠. Estoy escribiendo para confirmar un pedido que he realizado recientemente. Melissa, que es mi amiga, se ha encargado de hacer algunas compritas interesantes. \n",
      "\n",
      "## Informaci√≥n del Comprador\n",
      "\n",
      "Melissa Higgins es el nombre de la compradora. La √∫ltima vez que hablamos, me coment√≥ que su email es **melissa.higgins@gmail.com**. Si quisieran contactarla, podr√≠a ser a trav√©s de su tel√©fono que es m√°s o menos **740-913-5237**, o tambi√©n tiene una direcci√≥n alternativa, que es **christophercalderon@example.com**. \n",
      "\n",
      "Ella vive en varios lugares, porque, bueno, le gusta viajar. Entre sus direcciones hay una en **Caron**, Francia, espec√≠ficamente en el **51, chemin de Lebon** y el c√≥digo postal es el **55627**. Luego, tiene otra direcci√≥n en Alemania, en **Giorgio-Christoph-Weg 51-15, L√ºbz**, con el postal **91560**. No olvidemos la direcci√≥n en Canad√°: **3573 Chandler Rest Suite 810, Garrettmouth**, con el postal **K5M8S4**. A veces pienso que la gente deber√≠a quedase en un solo lugar!\n",
      "\n",
      "## Detalles de las Compras\n",
      "\n",
      "Hablando de su pedido, entre los productos que ella seleccion√≥ hay unas mo√±as UBL, creo que pidi√≥ tres (o quiz√°s eran cuatro, ya saben c√≥mo es Melissa). El precio de esas mo√±as deber√≠a estar en libras, tal vez alrededor de **¬£3** cada una, o algo as√≠. \n",
      "\n",
      "Luego, tambi√©n hab√≠a una base compacta en polvo (esto es algo que probablemente se usa para el maquillaje), en un tono llamado \"efecto total 6 avellana Vogue\", creo que solo pidi√≥ una de esas y costaba alrededor de **‚Ç¨30**. \n",
      "\n",
      "No puedo dejar de mencionar el vodka Absolut. Parece que ella se ha vuelto fan√°tico de √©l, porque pidi√≥ **m√°s de tres botellas**, creo que fueron unas cuatro. Ya saben como le gusta disfrutar de una buena bebida en las reuniones. El precio de eso ser√≠a en d√≥lares, probablemente unos **$20 cada botella**. \n",
      "\n",
      "## M√©todo de Env√≠o\n",
      "\n",
      "Por cierto, respecto a c√≥mo le gustar√≠a recibir su pedido, mencion√≥ algo sobre utilizar un m√©todo de env√≠o **normal** o ¬´standard¬ª. No s√© muy bien qu√© significa eso, quiz√°s un env√≠o m√°s tranquilo. Ella me coment√≥ que podr√≠a ser entregado a m√°s tardar el **14 de enero del a√±o 2023**, as√≠ que espero que no me olviden de eso. Alguna vez me pareci√≥ que ella prefer√≠a cosas r√°pidas, pero ahora le est√° gustando esperar, o eso es lo que dice (aunque en realidad siempre est√° pidiendo algo urgente, que lo env√≠en pronto, pero nunca durante los fines de semana, es un poco confuso!).\n",
      "\n",
      "As√≠ que, en resumen, haga lo que tenga que hacer, pero espero que todo salga bien con este pedido de Melissa. ¬°La √∫ltima vez el ron estuvo exquisito, espero que no se me olvide hacer otra reuni√≥n pronto! Llevar√© a cabo el env√≠o en cuanto se puedan. üòä\n",
      "\n",
      "JSON:\n",
      "{\"buyer\": {\"addresses\": [{\"city\": \"Caron\", \"country\": \"FR\", \"postal_code\": \"55627\", \"state\": null, \"street\": \"51, chemin de Lebon\"}, {\"city\": \"L√ºbz\", \"country\": \"DE\", \"postal_code\": \"91560\", \"state\": null, \"street\": \"Giorgio-Christoph-Weg 51-15\"}, {\"city\": \"Garrettmouth\", \"country\": \"CA\", \"postal_code\": \"K5M8S4\", \"state\": null, \"street\": \"3573 Chandler Rest Suite 810\"}], \"contact\": {\"alt_email\": \"christophercalderon@example.com\", \"phone\": \"740-913-5237\", \"preferred_contact\": \"none\"}, \"email\": \"melissa.higgins@gmail.com\", \"name\": \"Melissa Higgins\"}, \"purchases\": [{\"currency\": \"GBP\", \"discount_code\": null, \"product_name\": \"UBL moza UBL moza UBL moza UBL moza UBL moza UBL moza UBL moza UBL mo\n",
      "Pred_normalizado: {'buyer': {'name': None, 'email': None, 'contact': None, 'addresses': None}, 'purchases': None, 'shipping': None}\n",
      "True: {'buyer': {'addresses': [{'city': 'Caron', 'country': 'FR', 'postal_code': '55627', 'state': None, 'street': '51, chemin de Lebon'}, {'city': 'L√ºbz', 'country': 'DE', 'postal_code': '91560', 'state': None, 'street': 'Giorgio-Christoph-Weg 51-15'}, {'city': 'Garrettmouth', 'country': 'CA', 'postal_code': 'K5M8S4', 'state': None, 'street': '3573 Chandler Rest Suite 810'}], 'contact': {'alt_email': 'christophercalderon@example.com', 'phone': '7409135237', 'preferred_contact': None}, 'email': 'melissa.higgins@gmail.com', 'name': 'Melissa Higgins'}, 'purchases': [{'currency': 'GBP', 'discount_code': None, 'product_name': 'Mo√±as UBL ', 'quantity': 3}, {'currency': 'EUR', 'discount_code': None, 'product_name': 'Base compacta polvo efecto total 6 avellana Vogue ', 'quantity': 1}, {'currency': 'USD', 'discount_code': None, 'product_name': 'Vodka Absolut ', 'quantity': 4}], 'shipping': {'method': 'standard', 'preferred_by': '2023-01-14T17:55:04'}}\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "27 0.03398058252427184\n",
      "Texto: Eres un extractor de √≥rdenes. Genera SOLO un JSON v√°lido EXACTAMENTE con los campos requeridos.\n",
      "Reglas:\n",
      "- Usa null cuando un campo no exista.\n",
      "- \"buyer\" debe existir; si name/email/contact/addresses faltan, d√©jalos en null.\n",
      "- Si addresses est√° vac√≠o o no existe -> \"addresses\": null.\n",
      "- Si purchases est√° vac√≠o o no existe -> \"purchases\": null.\n",
      "- shipping es opcional; si falta -> \"shipping\": null.\n",
      "- Asegura que los tipos principales sean correctos (quantity entero, country uno de US/CA/GB/ES/CO/DE/FR).\n",
      "\n",
      "Texto:\n",
      "¬°Hola! üòä Espero que est√©s bien. Quer√≠a hacer un pedido parecido al que hice la otra vez, si puedes ayudarme. Estoy interesada en unas arepas de queso con ch√≠a, necesito m√°s o menos dos. ü•≥ Tambi√©n me gustar√≠a pedir un par de esos ricos ring cakes de naranja, ¬øte acord√°s? Esa mezcla de sabores es simplemente incre√≠ble. ¬°Ah! Y no te olvides de incluir unas seis leches colanta enteras, son las mejores para el desayuno, ¬øno crees? ü•õ\n",
      "\n",
      "Sobre la entrega, preferir√≠a recogerlo. No me viene bien que me lo env√≠en este fin de semana, as√≠ que quiz√°s podamos coordinarlo para el pr√≥ximo lunes. üåû Estoy en Bruneau, en la rue Claudine Albert, por si acaso, el c√≥digo postal es 90546, en Francia. Pero si no te es conveniente, tambi√©n puedo pasar por Luckau o Stade, que son en Alemania y tengo esas direcciones listas tambi√©n.\n",
      "\n",
      "Si ten√©s alguna pregunta, pod√©s escribirme a mi correo, que es lori.wood1@hotmail.com, aunque mi tel√©fono es preferido, me lo puedes pedir si hace falta. Por cierto, ayer llovi√≥ por aqu√≠ y me qued√© en casa, ¬°menos mal que ten√≠a algunos snacks! üçï \n",
      "\n",
      "Espero tu respuesta pronto. ¬°Gracias!\n",
      "\n",
      "JSON:\n",
      "{\"buyer\": {\"addresses\": [{\"city\": \"Bruneau\", \"country\": \"FR\", \"postal_code\": \"90546\", \"state\": null, \"street\": \"Rue Claudine Albert\"}, {\"city\": \"Luckau\", \"country\": \"DE\", \"postal_code\": \"21100\", \"state\": null, \"street\": \"Rue de la Catedral\"}, {\"city\": \"Stade\", \"country\": \"DE\", \"postal_code\": \"21100\", \"state\": null, \"street\": \"Rue de la Catedral\"}], \"contact\": {\"alt_email\": \"lori.wood1@hotmail.com\", \"phone\": \"0401-234-5678\", \"preferred_contact\": \"none\"}, \"email\": \"lori.wood1@hotmail.com\", \"name\": \"Lori Wood\"}, \"purchases\": [{\"currency\": \"EUR\", \"discount_code\": null, \"product_name\": \"Arepas de queso con ch√≠a \", \"quantity\": 2}, {\"currency\": \"EUR\", \"discount_code\": null, \"product_name\": \"Rico ring cake naranja \", \"quantity\": 6\n",
      "Pred_normalizado: {'buyer': {'name': None, 'email': None, 'contact': None, 'addresses': None}, 'purchases': None, 'shipping': None}\n",
      "True: {'buyer': {'addresses': [{'city': 'Bruneau', 'country': 'FR', 'postal_code': '90546', 'state': None, 'street': '5, rue Claudine Albert'}, {'city': 'Luckau', 'country': 'DE', 'postal_code': '68921', 'state': None, 'street': 'Maike-Boucsein-Gasse 2/7'}, {'city': 'Stade', 'country': 'DE', 'postal_code': '84901', 'state': None, 'street': 'Jana-Fr√∂hlich-Ring 15-11'}], 'contact': {'alt_email': 'meganrivera@example.com', 'phone': None, 'preferred_contact': 'phone'}, 'email': 'lori.wood1@hotmail.com', 'name': 'Lori Wood'}, 'purchases': [{'currency': 'EUR', 'discount_code': None, 'product_name': 'Arepas de queso con semilla de ch√≠a don ma√≠z ', 'quantity': 2}, {'currency': 'GBP', 'discount_code': None, 'product_name': 'Ring cake naranja ', 'quantity': 2}, {'currency': None, 'discount_code': None, 'product_name': 'Leche colanta entera litron ', 'quantity': 6}], 'shipping': {'method': 'pickup', 'preferred_by': '2023-01-27T05:54:40'}}\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "18 0.038781163434903045\n",
      "Texto: Eres un extractor de √≥rdenes. Genera SOLO un JSON v√°lido EXACTAMENTE con los campos requeridos.\n",
      "Reglas:\n",
      "- Usa null cuando un campo no exista.\n",
      "- \"buyer\" debe existir; si name/email/contact/addresses faltan, d√©jalos en null.\n",
      "- Si addresses est√° vac√≠o o no existe -> \"addresses\": null.\n",
      "- Si purchases est√° vac√≠o o no existe -> \"purchases\": null.\n",
      "- shipping es opcional; si falta -> \"shipping\": null.\n",
      "- Asegura que los tipos principales sean correctos (quantity entero, country uno de US/CA/GB/ES/CO/DE/FR).\n",
      "\n",
      "Texto:\n",
      "# Orden de Compra de Kelly Wang\n",
      "\n",
      "Hola, soy Kelly. Espero que est√©s disfrutando del clima bonito; de hecho, ayer estuvo nublado y me record√≥ que ya se acerca el invierno. üôà \n",
      "\n",
      "Quer√≠a compartir los detalles de mi reciente pedido. Estoy emocionada porque he encontrado unas cosas muy interesantes. Entre las compras, inclu√≠ algo que me encanta, el famoso vino Casillero del Diablo. Ped√≠ una cantidad decente, como tres botellas. üç∑ ¬°No puedo esperar a disfrutarlo con una buena cena!\n",
      "\n",
      "Por cierto, no olvides que ped√≠ tambi√©n unas seis unidades de mantequilla. Esa colanta de 125 gramos es simplemente deliciosa y es como la que compr√© la vez pasada, no puedo dejar de tenerla. Tambi√©n fui un poco generosa con unos mini croissants; son diez, ¬°s√≠, diez! Son tan irresistibles, especialmente con un caf√© por las ma√±anas. ‚òïÔ∏è \n",
      "\n",
      "En cuanto a la forma de env√≠o, prefer√≠ recogida, como siempre. A veces me gusta salir un ratito y respirar aire fresco, pero sin ning√∫n apuro. Pero s√≠, ser√≠a genial si pudieras darme alg√∫n dato sobre cu√°ndo estar√≠a listo. Si puedes, intenta hacerlo antes del pr√≥ximo fin de semana, pero no te estreses, quiz√°s el lunes est√© bien tambi√©n.\n",
      "\n",
      "Me gustar√≠a que supieras que tengo varias direcciones donde podr√≠an enviarlo, aunque esta vez lo recoja yo misma. Una est√° en Holmeview, con c√≥digo postal L8E 7H3, y la otra en Palermo, en Diagonal 73, n√∫mero 5-40 Sur, con un c√≥digo que empieza con 661. A veces es complicado elegir la direcci√≥n, pero esta vez no deber√≠an haber problemas.\n",
      "\n",
      "Por cierto, aqu√≠ tienes mis datos de contacto. Puedes localizarme a trav√©s de mi correo kelly.wang375@gmail.com, o si prefieres, puedes darme un toque al 500.792.7401 x37037. Aunque, para ser honesta, no tengo una preferencia clara sobre c√≥mo me contactas, ¬°est√° bien lo que sea! \n",
      "\n",
      "Espero que todo est√© claro, y tengo muchas ganas de que lleguen mis cosas. \n",
      "\n",
      "Gracias por tu atenci√≥n y ¬°abrazos!\n",
      "\n",
      "JSON:\n",
      "{\"buyer\": {\"addresses\": [{\"city\": \"Holmeview\", \"country\": \"CA\", \"postal_code\": \"L8E 7H3\", \"state\": null, \"street\": \"1000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n",
      "Pred_normalizado: {'buyer': {'name': None, 'email': None, 'contact': None, 'addresses': None}, 'purchases': None, 'shipping': None}\n",
      "True: {'buyer': {'addresses': [{'city': 'Holmesview', 'country': 'CA', 'postal_code': 'L8E 7H3', 'state': None, 'street': '44857 Richards Crossing'}, {'city': 'Palermo', 'country': 'CO', 'postal_code': '661437', 'state': None, 'street': 'Diagonal 73 # 5-40 Sur'}], 'contact': {'alt_email': None, 'phone': '500.792.7401x37037', 'preferred_contact': 'none'}, 'email': 'kelly.wang375@gmail.com', 'name': 'Kelly Wang'}, 'purchases': [{'currency': 'EUR', 'discount_code': None, 'product_name': 'Vino Casillero del Diablo red blend botella ', 'quantity': 3}, {'currency': None, 'discount_code': None, 'product_name': 'Mantequilla colanta-125g', 'quantity': 6}, {'currency': 'GBP', 'discount_code': None, 'product_name': 'Mini viennoiseria ', 'quantity': 10}], 'shipping': {'method': 'pickup', 'preferred_by': None}}\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Mostrar peores 3 ejemplos\n",
    "sorted_by_f1 = sorted(results, key=lambda x: x['f1'])\n",
    "print('\\nPeores 3 ejemplos:')\n",
    "for r in sorted_by_f1[:3]:\n",
    "    print(r['idx'], r['f1'])\n",
    "    print('Texto:', r['raw'])\n",
    "    print('Pred_normalizado:', r['pred_norm'])\n",
    "    print('True:', r['true'])\n",
    "    print('-'*150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a6e0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Guardar modelo adaptado final (LoRA adapter + tokenizer)\n",
    "model.save_pretrained(os.path.join(OUTPUT_DIR, 'final_lora_adapter'))\n",
    "tokenizer.save_pretrained(os.path.join(OUTPUT_DIR, 'final_tokenizer'))\n",
    "print('Artefactos guardados en', OUTPUT_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_312_CUDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
