{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento con GPU - Versi√≥n Optimizada\n",
    "**Nota:** Este notebook est√° optimizado exclusivamente para GPU con cuantizaci√≥n 4-bit y AMP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "from typing import Any, Dict, List, Optional\n",
    "import csv\n",
    "import time\n",
    "import datetime as dt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset as TorchDataset\n",
    "from torch.optim import AdamW\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.utils.checkpoint\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Importar archivos .py personalizados\n",
    "import evaluation_metric as custom_metrics\n",
    "import shared_functions as custom_sharfun\n",
    "\n",
    "from importlib.metadata import version\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    get_scheduler\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from transformers import logging as hf_logging\n",
    "hf_logging.set_verbosity_warning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(\"Inicio de ejecuci√≥n:\", dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versiones utilizadas\n",
    "librerias = [\n",
    "    \"numpy\",\n",
    "    \"matplotlib\",\n",
    "    \"torch\",\n",
    "    \"tqdm\",\n",
    "    \"datasets\",\n",
    "    \"transformers\",\n",
    "    \"peft\",\n",
    "    \"importlib-metadata\"\n",
    "]\n",
    "for library in librerias:\n",
    "    print(library, \": \", version(library))\n",
    "\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuraci√≥n GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar GPU\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"‚ö†Ô∏è GPU no disponible. Este notebook requiere GPU para ejecutarse.\")\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"üöÄ ENTRENAMIENTO CON GPU\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"Memoria GPU disponible: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n base\n",
    "TOTAL_FILES_TO_TRAIN = 9\n",
    "DATA_PATH = \"data/train\"\n",
    "OUTPUT_DIR = \"output/results/v01\"\n",
    "EXPECTED_JSON_FILE = \"data/template/expected_output.json\"\n",
    "EXPECTED_JSON = None\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "MODEL_NAME = \"Qwen/Qwen3-0.6B-Base\"\n",
    "\n",
    "# Seeds\n",
    "GLB_SEED = 42\n",
    "torch.manual_seed(GLB_SEED)\n",
    "random.seed(GLB_SEED)\n",
    "np.random.seed(GLB_SEED)\n",
    "torch.cuda.manual_seed_all(GLB_SEED)\n",
    "\n",
    "# Par√°metros comunes\n",
    "TEST_SIZE = 0.2\n",
    "MAX_LENGTH = 1252\n",
    "\n",
    "# Par√°metros optimizados para GPU\n",
    "BATCH_SIZE = 8\n",
    "GRAD_ACCUM_STEPS = 2\n",
    "EPOCHS = 5\n",
    "WARMUP_RATIO = 0.03\n",
    "LEARNING_RATE = 2e-4\n",
    "WEIGHT_DECAY = 0.01\n",
    "BETAS = (0.9, 0.999)\n",
    "EPS = 1e-8\n",
    "SCHEDULER_TYPE = \"linear\"\n",
    "CLIP_NORM = 1.0\n",
    "\n",
    "# LoRA - Configuraci√≥n agresiva para GPU\n",
    "LORA_R = 64\n",
    "LORA_ALPHA = 128\n",
    "LORA_DROPOUT = 0.05\n",
    "TARGET_MODULES = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
    "\n",
    "# Generaci√≥n\n",
    "NUM_VAL_EXAMPLES = 45\n",
    "GEN_MAX_NEW_TOKENS = 377\n",
    "BEAM_CANDIDATES = 5\n",
    "\n",
    "# Imprimir configuraci√≥n\n",
    "print(f\"\\nüìä CONFIGURACI√ìN GPU:\")\n",
    "print(f\"  - Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  - Gradient Accumulation Steps: {GRAD_ACCUM_STEPS}\")\n",
    "print(f\"  - Epochs: {EPOCHS}\")\n",
    "print(f\"  - Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"  - LoRA R: {LORA_R}\")\n",
    "print(f\"  - LoRA Alpha: {LORA_ALPHA}\")\n",
    "print(f\"  - Target Modules: {TARGET_MODULES}\")\n",
    "print(f\"  - Cuantizaci√≥n 4-bit: ‚úì Activada\")\n",
    "print(f\"  - Mixed Precision (AMP): ‚úì Activada\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar archivo ejemplo JSON esperado\n",
    "if os.path.exists(EXPECTED_JSON_FILE):\n",
    "    with open(EXPECTED_JSON_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        EXPECTED_JSON = json.load(f)\n",
    "    print(f\"‚úÖ Archivo template cargado: {EXPECTED_JSON_FILE}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Archivo template no encontrado: {EXPECTED_JSON_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos de entrenamiento\n",
    "raw_data = []\n",
    "files = sorted([f for f in os.listdir(DATA_PATH) if f.endswith(\".json\")])[:TOTAL_FILES_TO_TRAIN]\n",
    "\n",
    "for file_name in files:\n",
    "    file_path = os.path.join(DATA_PATH, file_name)\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        if isinstance(data, list):\n",
    "            raw_data.extend(data)\n",
    "        elif isinstance(data, dict):\n",
    "            raw_data.append(data)\n",
    "        else:\n",
    "            raise ValueError(f\"Formato no esperado en {file_name}\")\n",
    "\n",
    "print(f\"Total training files loaded: {len(raw_data)}\")\n",
    "\n",
    "clean_data = []\n",
    "dropped = 0\n",
    "for item in raw_data:\n",
    "    natural = item.get(\"natural_language\")\n",
    "    json_d = item.get(\"json_data\")\n",
    "    if natural is None or natural == \"\" or json_d is None:\n",
    "        dropped += 1\n",
    "        continue\n",
    "    clean_data.append(item)\n",
    "\n",
    "print(f\"Registros v√°lidos despu√©s de limpiar: {len(clean_data)} (eliminados: {dropped})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a Hugging Face Dataset\n",
    "hf_dataset = Dataset.from_list(clean_data)\n",
    "\n",
    "# Split train / validation\n",
    "split = hf_dataset.train_test_split(test_size=TEST_SIZE, seed=GLB_SEED)\n",
    "train_list = split['train']\n",
    "val_list = split['test']\n",
    "\n",
    "print(f\"Train examples: {len(train_list)}, Val examples: {len(val_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuci√≥n de longitudes\n",
    "longitudes = [len(item[\"natural_language\"]) for item in clean_data if item.get(\"natural_language\") is not None]\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(longitudes, bins=20)\n",
    "plt.title(\"Distribuci√≥n de longitudes de 'natural_language'\")\n",
    "plt.xlabel(\"Longitud del texto\")\n",
    "plt.ylabel(\"Cantidad de ejemplos\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar modelo y tokenizer (GPU con cuantizaci√≥n 4-bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cargando tokenizer y modelo con cuantizaci√≥n 4-bit...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Configuraci√≥n 4-bit\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Preparar para k-bit training\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# Desactivar cache y habilitar checkpointing\n",
    "model.config.use_cache = False\n",
    "try:\n",
    "    model.gradient_checkpointing_enable(gradient_checkpointing_kwargs={\"use_reentrant\": False})\n",
    "except TypeError:\n",
    "    model.gradient_checkpointing_enable()\n",
    "\n",
    "# Configurar LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=LORA_R,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    target_modules=TARGET_MODULES,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An√°lisis de longitudes de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths_tokens = []\n",
    "for ex in clean_data:\n",
    "    txt = custom_sharfun.build_training_example(ex)\n",
    "    enc = tokenizer(txt, truncation=False, padding=False)\n",
    "    lengths_tokens.append(len(enc[\"input_ids\"]))\n",
    "\n",
    "print(\"Percentiles de longitudes (90, 95, 99):\")\n",
    "print(np.percentile(lengths_tokens, [90, 95, 99]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def medir_longitudes_tokens(dataset, tokenizer, max_ejemplos=None):\n",
    "    prompt_lens = []\n",
    "    json_lens = []\n",
    "    full_lens = []\n",
    "    \n",
    "    for i, ex in enumerate(dataset):\n",
    "        if max_ejemplos is not None and i >= max_ejemplos:\n",
    "            break\n",
    "        \n",
    "        natural = ex[\"natural_language\"]\n",
    "        target_json_str = json.dumps(ex[\"json_data\"], ensure_ascii=False)\n",
    "        prompt = custom_sharfun.build_prompt(natural)\n",
    "        full_text = prompt + target_json_str\n",
    "        \n",
    "        enc_prompt = tokenizer(prompt, truncation=False, padding=False, add_special_tokens=True)\n",
    "        enc_full = tokenizer(full_text, truncation=False, padding=False, add_special_tokens=True)\n",
    "        \n",
    "        lp = len(enc_prompt[\"input_ids\"])\n",
    "        lf = len(enc_full[\"input_ids\"])\n",
    "        lj = lf - lp\n",
    "        \n",
    "        prompt_lens.append(lp)\n",
    "        full_lens.append(lf)\n",
    "        json_lens.append(lj)\n",
    "    \n",
    "    stats = {\n",
    "        \"prompt_mean\": float(np.mean(prompt_lens)),\n",
    "        \"prompt_p95\": float(np.percentile(prompt_lens, 95)),\n",
    "        \"prompt_p99\": float(np.percentile(prompt_lens, 99)),\n",
    "        \"json_mean\": float(np.mean(json_lens)),\n",
    "        \"json_p95\": float(np.percentile(json_lens, 95)),\n",
    "        \"json_p99\": float(np.percentile(json_lens, 99)),\n",
    "        \"full_mean\": float(np.mean(full_lens)),\n",
    "        \"full_p95\": float(np.percentile(full_lens, 95)),\n",
    "        \"full_p99\": float(np.percentile(full_lens, 99)),\n",
    "        \"full_max\": int(np.max(full_lens)),\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "stats_val = medir_longitudes_tokens(val_list, tokenizer, max_ejemplos=None)\n",
    "print(\"Estad√≠sticas de validaci√≥n:\")\n",
    "print(stats_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparar DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizar datos\n",
    "train_tokens = [\n",
    "    custom_sharfun.tokenize_example_textpair(\n",
    "        custom_sharfun.build_training_example(x), \n",
    "        MAX_LENGTH, \n",
    "        tokenizer, \n",
    "        padding=False\n",
    "    ) for x in train_list\n",
    "]\n",
    "val_tokens = [\n",
    "    custom_sharfun.tokenize_example_textpair(\n",
    "        custom_sharfun.build_training_example(x), \n",
    "        MAX_LENGTH, \n",
    "        tokenizer, \n",
    "        padding=False\n",
    "    ) for x in val_list\n",
    "]\n",
    "\n",
    "# Simple Dataset\n",
    "class SimpleTorchDataset(TorchDataset):\n",
    "    def __init__(self, tokens_list):\n",
    "        self.data = tokens_list\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return {k: v for k, v in self.data[idx].items()}\n",
    "\n",
    "train_dataset = SimpleTorchDataset(train_tokens)\n",
    "val_dataset = SimpleTorchDataset(val_tokens)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids = [b['input_ids'] for b in batch]\n",
    "    attention_mask = [b['attention_mask'] for b in batch]\n",
    "    labels = [b['labels'] for b in batch]\n",
    "\n",
    "    input_ids = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    attention_mask = pad_sequence(attention_mask, batch_first=True, padding_value=0)\n",
    "    labels = pad_sequence(labels, batch_first=True, padding_value=-100)\n",
    "\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurar optimizador y scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steps_per_epoch = math.ceil(len(train_loader) / GRAD_ACCUM_STEPS)\n",
    "total_training_steps = EPOCHS * total_steps_per_epoch\n",
    "num_warmup_steps = int(total_training_steps * WARMUP_RATIO)\n",
    "\n",
    "print(f\"Total training steps: {total_training_steps}, Warmup steps: {num_warmup_steps}\")\n",
    "\n",
    "trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = AdamW(trainable_params, lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY, betas=BETAS, eps=EPS)\n",
    "\n",
    "scheduler = get_scheduler(\n",
    "    name=SCHEDULER_TYPE, \n",
    "    optimizer=optimizer, \n",
    "    num_warmup_steps=num_warmup_steps, \n",
    "    num_training_steps=total_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento con AMP (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar scaler para AMP\n",
    "print(\"üöÄ Usando Mixed Precision Training (AMP) con GPU\")\n",
    "scaler = torch.amp.GradScaler(device='cuda')\n",
    "\n",
    "model.to(DEVICE)\n",
    "model.train()\n",
    "\n",
    "global_step = 0\n",
    "optimizer.zero_grad()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for step, batch in pbar:\n",
    "        input_ids = batch['input_ids'].to(DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "        labels = batch['labels'].to(DEVICE)\n",
    "\n",
    "        # Forward pass con AMP\n",
    "        with torch.amp.autocast(device_type='cuda'):\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss / GRAD_ACCUM_STEPS\n",
    "        \n",
    "        # Backward pass con scaler\n",
    "        scaler.scale(loss).backward()\n",
    "        running_loss += loss.item() * GRAD_ACCUM_STEPS\n",
    "\n",
    "        # Update block\n",
    "        if (step + 1) % GRAD_ACCUM_STEPS == 0 or (step + 1) == len(train_loader):\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP_NORM)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "\n",
    "            avg_loss = running_loss / (step + 1)\n",
    "            pbar.set_postfix({'loss': f\"{avg_loss:.4f}\", 'lr': scheduler.get_last_lr()[0]})\n",
    "\n",
    "    print(f\"Epoch {epoch+1} finished ‚Äî avg loss: {running_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR_MODEL = os.path.join(OUTPUT_DIR, \"modfinal\")\n",
    "os.makedirs(OUTPUT_DIR_MODEL, exist_ok=True)\n",
    "\n",
    "model.save_pretrained(OUTPUT_DIR_MODEL)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR_MODEL)\n",
    "\n",
    "print('Modelo guardado en', OUTPUT_DIR_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_PATH = os.path.join(OUTPUT_DIR_MODEL, \"weights.pt\")\n",
    "torch.save(\n",
    "    {\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"tokenizer\": tokenizer.__dict__,\n",
    "    },\n",
    "    CKPT_PATH\n",
    ")\n",
    "print(\"Checkpoint .pt guardado en:\", CKPT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tama√±o conjunto de validaci√≥n:\", len(val_list))\n",
    "NUM_VAL_EXAMPLES = len(val_list)\n",
    "\n",
    "results = []\n",
    "for idx, ex in enumerate(\n",
    "    tqdm(val_list.select(range(min(NUM_VAL_EXAMPLES, len(val_list)))), desc=\"Eval\")\n",
    "):\n",
    "    text = ex[\"natural_language\"]\n",
    "    raw = custom_sharfun.generate_json_raw(\n",
    "        text=text, \n",
    "        max_new_tokens=GEN_MAX_NEW_TOKENS, \n",
    "        max_length=MAX_LENGTH, \n",
    "        tokenizer=tokenizer, \n",
    "        model=model, \n",
    "        device=DEVICE\n",
    "    )\n",
    "    pred_obj = custom_sharfun.extract_json_from_text(raw)\n",
    "    true_json = ex[\"json_data\"]\n",
    "\n",
    "    if pred_obj is None:\n",
    "        f1 = 0.0\n",
    "    else:\n",
    "        try:\n",
    "            f1 = custom_metrics.evaluate_json(true_json, json.dumps(pred_obj, ensure_ascii=False))\n",
    "        except Exception:\n",
    "            f1 = float(1.0 if pred_obj == true_json else 0.0)\n",
    "\n",
    "    print(f\"Ejemplo {idx}: F1 = {f1:.4f}\")\n",
    "    results.append({\"idx\": idx, \"f1\": f1, \"raw\": raw, \"pred\": pred_obj, \"true\": true_json})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico de F1 scores\n",
    "f1_scores = [r['f1'] for r in results]\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(range(1, len(f1_scores) + 1), f1_scores, marker='o')\n",
    "plt.title(\"F1 Scores por Ejemplo de Validaci√≥n\")\n",
    "plt.xlabel(\"Ejemplo de Validaci√≥n\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar resultados\n",
    "OUTPUT_DIR_VAL = os.path.join(OUTPUT_DIR, \"result_validation\")\n",
    "os.makedirs(OUTPUT_DIR_VAL, exist_ok=True)\n",
    "csv_path = os.path.join(OUTPUT_DIR_VAL, 'validation_results.csv')\n",
    "\n",
    "with open(csv_path, 'w', encoding='utf-8', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['idx','f1','raw','pred','true'])\n",
    "    writer.writeheader()\n",
    "    for r in results:\n",
    "        writer.writerow({\n",
    "            'idx': r['idx'],\n",
    "            'f1': r['f1'],\n",
    "            'raw': r['raw'],\n",
    "            'pred': json.dumps(r['pred'], ensure_ascii=False),\n",
    "            'true': json.dumps(r['true'], ensure_ascii=False)\n",
    "        })\n",
    "print('CSV guardado en', csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma F1\n",
    "f1_scores = [r['f1'] for r in results]\n",
    "plt.figure()\n",
    "plt.hist(f1_scores, bins=10)\n",
    "plt.title('Distribuci√≥n de F1')\n",
    "plt.xlabel('F1')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'f1_distribution.png'))\n",
    "plt.show()\n",
    "plt.close()\n",
    "print('Histograma guardado en', os.path.join(OUTPUT_DIR, 'f1_distribution.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar peores 3 ejemplos\n",
    "sorted_by_f1 = sorted(results, key=lambda x: x['f1'])\n",
    "print('\\nPeores 3 ejemplos:')\n",
    "for r in sorted_by_f1[:3]:\n",
    "    print(f\"Ejemplo #{r['idx']} - F1 Score: {r['f1']}\")\n",
    "    print('Texto:', r['raw'])\n",
    "    print(\"*\"*90)\n",
    "    print('Pred_normalizado:', r['pred'])\n",
    "    print('True:', r['true'])\n",
    "    print('-'*150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "elapsed_sec = end_time - start_time\n",
    "elapsed_min = elapsed_sec / 60\n",
    "\n",
    "print(f\"Fin de ejecuci√≥n: {dt.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Tiempo total: {elapsed_sec:.1f} segundos (~{elapsed_min:.2f} minutos)\")\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"‚úÖ Entrenamiento completado con GPU\")\n",
    "print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (new_entorno_2)",
   "language": "python",
   "name": "new_entorno_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
