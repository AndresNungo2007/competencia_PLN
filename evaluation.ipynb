{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f2d3188",
   "metadata": {},
   "source": [
    "# Evaluación\n",
    "\n",
    "**Rúbrica:** Este archivo debe incluir las funciones creadas para la generación de los JSONs para los correos de prueba de la partición de test. Asegúrense de que este archivo cargue los pesos de weights.pt y lea directamente el archivo eval.json.\n",
    "\n",
    "Este notebook genera el archivo `submission.csv` para subir a Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd10e70",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3041fd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "from typing import Any, Dict, List, Optional\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shared_functions as custom_sharfun  #el archivo .py con funciones compartidas\n",
    "\n",
    "from peft import PeftModel, LoraConfig\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from transformers import logging as hf_logging\n",
    "hf_logging.set_verbosity_warning()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a56d9a",
   "metadata": {},
   "source": [
    "# Cargar el modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad0ddef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorios y modelos\n",
    "OUTPUT_DIR = \"output/results/v10\"\n",
    "ADAPTER_DIR = os.path.join(OUTPUT_DIR, \"modfinal_full\")\n",
    "\n",
    "# Configuración del dispositivo\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a397a0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_file = os.path.join(ADAPTER_DIR, \"weights.pt\")\n",
    "pt_loaded = torch.load(pt_file, map_location=DEVICE)\n",
    "\n",
    "print(\"Cargando tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(pt_loaded[\"tokenizer\"])\n",
    "tokenizer.padding_side = \"left\" # A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(\"Cargando modelo base en 4 bits...\")\n",
    "bnb_config = BitsAndBytesConfig(**pt_loaded[\"bnb_config\"])\n",
    "\n",
    "print(\"Modelo base:\", pt_loaded[\"model_id\"])\n",
    "model_base = AutoModelForCausalLM.from_pretrained(\n",
    "    pt_loaded[\"model_id\"],\n",
    "    quantization_config=bnb_config, \n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "print(\"Cargando modelo LoRA...\")\n",
    "# Debes usar la misma configuración LoRA que usaste al entrenar\n",
    "config_lora = LoraConfig(\n",
    "    r = pt_loaded[\"config\"][\"lora_r\"],\n",
    "    lora_alpha = pt_loaded[\"config\"][\"lora_alpha\"],\n",
    "    lora_dropout = pt_loaded[\"config\"][\"lora_drop\"],\n",
    "    target_modules = pt_loaded[\"config\"][\"lora_target_mods\"],\n",
    "    bias=pt_loaded[\"config\"][\"lora_bias\"],\n",
    "    task_type=pt_loaded[\"config\"][\"lora_task_type\"]\n",
    ")\n",
    "\n",
    "model = PeftModel(model_base, config_lora)\n",
    "model.load_state_dict(pt_loaded[\"peft\"], strict=False)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ee0567",
   "metadata": {},
   "source": [
    "⚠️ **Advertencia**   \n",
    "En las pruebas de validación se detectó que se debe aumentar MAX_LENGTH y GEN_MAX_NEW_TOKENS para que genere el JSON completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466599b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data / tokenization\n",
    "MAX_LENGTH = 2048\n",
    "# Evaluación\n",
    "GEN_MAX_NEW_TOKENS = 512\n",
    "BATCH_SIZE_EVAL = 14 # ajustar según memoria GPU para ejecutar más rápido la evaluación\n",
    "\n",
    "# Semilla de entrenamiento\n",
    "GLB_SEED = pt_loaded[\"config\"][\"seed\"]\n",
    "torch.manual_seed(GLB_SEED)\n",
    "random.seed(GLB_SEED)\n",
    "np.random.seed(GLB_SEED)\n",
    "if DEVICE == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(GLB_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfbf188",
   "metadata": {},
   "source": [
    "# Carga de datos\n",
    "`eval.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addab50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/eval/eval.json\" \n",
    "with open(DATA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_data = json.load(f)\n",
    "print(f\"Número de ejemplos de evaluación: {len(raw_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9973f767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener longitudes - histograma\n",
    "longitudes = [len(item[\"natural_language\"]) for item in raw_data]\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(longitudes, bins=20)  # puedes ajustar el número de bins\n",
    "plt.title(\"Distribución de longitudes de 'natural_language'\")\n",
    "plt.xlabel(\"Longitud del texto\")\n",
    "plt.ylabel(\"Cantidad de ejemplos\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dafb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar directamente un archivo JSON\n",
    "val_list = load_dataset('json', data_files=DATA_PATH)['train']\n",
    "print(type(val_list))  # Será datasets.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48c72c9",
   "metadata": {},
   "source": [
    "### Funciones para procesar por lotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c0e9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_json_raw_batch( texts: List[str], tokenizer, model, device, max_new_tokens: int, max_length: int, batch_size: int = 8):\n",
    "    outputs = []\n",
    "    pad_id = tokenizer.pad_token_id or tokenizer.eos_token_id\n",
    "    #eos_brace_id = tokenizer.encode(\"}\", add_special_tokens=False)[0]\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Generating\", total=math.ceil(len(texts)/batch_size)):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        prompts = [custom_sharfun.build_prompt(t) for t in batch]\n",
    "\n",
    "        enc = tokenizer( prompts, return_tensors='pt', truncation=True, padding=\"longest\", max_length=max_length).to(device)\n",
    "        input_ids = enc[\"input_ids\"]\n",
    "        attention_mask = enc[\"attention_mask\"]\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            model.eval()\n",
    "            out = model.generate( \n",
    "                input_ids=input_ids, \n",
    "                attention_mask=attention_mask, \n",
    "                max_new_tokens=max_new_tokens, \n",
    "                do_sample=False, \n",
    "                pad_token_id=pad_id, \n",
    "                eos_token_id=tokenizer.eos_token_id, \n",
    "                use_cache=True\n",
    "            )\n",
    "\n",
    "        decoded = tokenizer.batch_decode(out, skip_special_tokens=True) # Decodificar outputs en lote\n",
    "\n",
    "        # Recorte final\n",
    "        cleaned = []\n",
    "        for d in decoded:\n",
    "            d = (d.replace(\"“\", '\"').replace(\"”\", '\"').replace(\"’\", \"'\"))\n",
    "\n",
    "            if \"{\" in d and \"}\" in d:\n",
    "                first = d.find(\"{\")\n",
    "                last = d.rfind(\"}\")\n",
    "                d = d[first:last+1]\n",
    "            cleaned.append(d)\n",
    "\n",
    "        outputs.extend(cleaned)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7db218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json_from_text(text: str):\n",
    "    \"\"\"\n",
    "    Escanea llaves para encontrar un bloque JSON bien balanceado.\n",
    "    \"\"\"\n",
    "    marker = '{\"buyer\":'\n",
    "    pos = text.find(marker)\n",
    "    if pos != -1:\n",
    "        start = text.find(marker)\n",
    "    else: # pos == -1\n",
    "        marker = \"\\nJSON:\\n\"\n",
    "        pos = text.find(marker)\n",
    "        if pos == -1:\n",
    "            start = text.find(\"{\")\n",
    "        else:\n",
    "            start = text.find(\"{\", pos + len(marker)) # Buscar la primera llave '{' después del marcador\n",
    "            if start == -1:\n",
    "                start = text.find(\"{\")\n",
    "\n",
    "    if start == -1:\n",
    "        return None\n",
    "\n",
    "    brace_count = 0\n",
    "    in_json = False\n",
    "\n",
    "    for i in range(start, len(text)):\n",
    "        if text[i] == \"{\":\n",
    "            brace_count += 1\n",
    "            in_json = True\n",
    "        elif text[i] == \"}\":\n",
    "            brace_count -= 1\n",
    "\n",
    "            # Si brace_count llega a 0 => JSON completo\n",
    "            if in_json and brace_count == 0:\n",
    "                candidate = text[start:i+1]\n",
    "\n",
    "                # intentar parsear\n",
    "                try:\n",
    "                    return json.loads(candidate)\n",
    "                except json.JSONDecodeError:\n",
    "                    # intento reemplazando comillas simples\n",
    "                    try:\n",
    "                        return json.loads(candidate.replace(\"'\", '\"'))\n",
    "                    except Exception:\n",
    "                        return None\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daede81",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "print(f\"Generando predicciones: total datos = {len(val_list)} ...\")\n",
    "\n",
    "texts = [ex[\"natural_language\"] for ex in val_list]\n",
    "ids = [ex[\"id\"] for ex in val_list]\n",
    "\n",
    "pred_raw_list = generate_json_raw_batch( texts=texts, tokenizer=tokenizer, model=model, device=DEVICE, max_new_tokens=GEN_MAX_NEW_TOKENS,  max_length=MAX_LENGTH, batch_size=BATCH_SIZE_EVAL )\n",
    "results_submission = []\n",
    "for id_save, raw in zip(ids, pred_raw_list):\n",
    "    pred_obj = extract_json_from_text(raw)\n",
    "    if pred_obj is None:\n",
    "        pred_obj = {}\n",
    "    results_submission.append({\n",
    "        \"id\": id_save,\n",
    "        \"prediction\": pred_obj\n",
    "    })\n",
    "\n",
    "end_time = time.time()\n",
    "print( custom_sharfun.print_time_execution(\"Generación de predicciones\", start_time, end_time) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b2a62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results2 = pd.DataFrame(results_submission, columns=[\"id\", \"prediction\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cae52bc",
   "metadata": {},
   "source": [
    "# Guardar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dd9662",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_DIR = os.path.join(OUTPUT_DIR, \"csvfinal\")\n",
    "os.makedirs(CSV_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd2f0c8",
   "metadata": {},
   "source": [
    "## Guardar copia en formato JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd10066",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_JSON2 = os.path.join(CSV_DIR, \"submission_2.json\")\n",
    "with open(OUTPUT_JSON2, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results_submission, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21c5869",
   "metadata": {},
   "source": [
    "## Guardar archivo CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db141e23",
   "metadata": {},
   "source": [
    "### Funciones para transformar datos antes de guardar a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48bec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_info(value):\n",
    "    if value is None:\n",
    "        return {}\n",
    "    return value\n",
    "\n",
    "def serialize_info(value):\n",
    "    if value is None:\n",
    "        value = {}\n",
    "    return json.dumps(value, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f601dfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_example_json_pred(js: Optional[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    # Si no hay salida, devolver estructura con nulls\n",
    "    if js is None or not isinstance(js, dict):\n",
    "        return {\n",
    "            \"buyer\": {\"name\": None, \"email\": None, \"contact\": None, \"addresses\": None},\n",
    "            \"purchases\": None,\n",
    "            \"shipping\": None,\n",
    "        }\n",
    "\n",
    "    out: Dict[str, Any] = {}\n",
    "\n",
    "    # BUYER\n",
    "    buyer = js.get(\"buyer\") if isinstance(js.get(\"buyer\"), dict) else (js.get(\"buyer\") if js.get(\"buyer\") is not None else None)\n",
    "    if not buyer or not isinstance(buyer, dict):\n",
    "        out[\"buyer\"] = {\"name\": None, \"email\": None, \"contact\": None, \"addresses\": None}\n",
    "    else:\n",
    "        out_buyer = {\n",
    "            \"name\": buyer.get(\"name\") if buyer.get(\"name\") is not None else None,\n",
    "            \"email\": buyer.get(\"email\") if buyer.get(\"email\") is not None else None,\n",
    "            \"contact\": None,\n",
    "            \"addresses\": None,\n",
    "        }\n",
    "        contact = buyer.get(\"contact\")\n",
    "        if contact and isinstance(contact, dict):\n",
    "            out_buyer[\"contact\"] = {\n",
    "                \"phone\": contact.get(\"phone\") if contact.get(\"phone\") is not None else None,\n",
    "                \"alt_email\": contact.get(\"alt_email\") if contact.get(\"alt_email\") is not None else None,\n",
    "                \"preferred_contact\": contact.get(\"preferred_contact\") if contact.get(\"preferred_contact\") is not None else None,\n",
    "            }\n",
    "        else:\n",
    "            out_buyer[\"contact\"] = None\n",
    "\n",
    "        addrs = buyer.get(\"addresses\")\n",
    "        if addrs and isinstance(addrs, list) and len(addrs) > 0:\n",
    "            out_addrs = []\n",
    "            for a in addrs:\n",
    "                if not isinstance(a, dict):\n",
    "                    continue\n",
    "                out_addrs.append(\n",
    "                    {\n",
    "                        \"street\": a.get(\"street\") if a.get(\"street\") is not None else None,\n",
    "                        \"city\": a.get(\"city\") if a.get(\"city\") is not None else None,\n",
    "                        \"state\": a.get(\"state\") if a.get(\"state\") is not None else None,\n",
    "                        \"postal_code\": a.get(\"postal_code\") if a.get(\"postal_code\") is not None else None,\n",
    "                        \"country\": a.get(\"country\") if a.get(\"country\") is not None else None,\n",
    "                    }\n",
    "                )\n",
    "            out_buyer[\"addresses\"] = out_addrs if out_addrs else None\n",
    "        else:\n",
    "            out_buyer[\"addresses\"] = None\n",
    "\n",
    "        out[\"buyer\"] = out_buyer\n",
    "\n",
    "    # PURCHASES\n",
    "    purchases = js.get(\"purchases\")\n",
    "    if purchases and isinstance(purchases, list) and len(purchases) > 0:\n",
    "        out_p = []\n",
    "        for p in purchases:\n",
    "            if not isinstance(p, dict):\n",
    "                continue\n",
    "            qty = p.get(\"quantity\")\n",
    "            qty_parsed = None\n",
    "            try:\n",
    "                if qty is not None:\n",
    "                    qty_parsed = int(qty)\n",
    "            except Exception:\n",
    "                qty_parsed = None\n",
    "            out_p.append(\n",
    "                {\n",
    "                    \"product_name\": p.get(\"product_name\") if p.get(\"product_name\") is not None else None,\n",
    "                    \"quantity\": qty_parsed,\n",
    "                    \"currency\": p.get(\"currency\") if p.get(\"currency\") is not None else None,\n",
    "                    \"discount_code\": p.get(\"discount_code\") if p.get(\"discount_code\") is not None else None,\n",
    "                }\n",
    "            )\n",
    "        out[\"purchases\"] = out_p if out_p else None\n",
    "    else:\n",
    "        out[\"purchases\"] = None\n",
    "\n",
    "    # SHIPPING\n",
    "    shipping = js.get(\"shipping\")\n",
    "    if shipping and isinstance(shipping, dict):\n",
    "        out[\"shipping\"] = {\n",
    "            \"method\": shipping.get(\"method\") if shipping.get(\"method\") is not None else None,\n",
    "            \"preferred_by\": shipping.get(\"preferred_by\") if shipping.get(\"preferred_by\") is not None else None,\n",
    "        }\n",
    "    else:\n",
    "        out[\"shipping\"] = None\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2138bca",
   "metadata": {},
   "source": [
    "### Transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f78b88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_normalized = df_results2.copy()\n",
    "df_results_normalized = df_results_normalized.copy()\n",
    "\n",
    "# Normalizar al esquema esperado\n",
    "df_results_normalized['normalized_prediction'] = df_results_normalized['prediction'].apply(lambda x: normalize_example_json_pred(x))\n",
    "\n",
    "df_results_normalized_csv = df_results_normalized[[\"id\", \"normalized_prediction\"]].copy()\n",
    "\n",
    "# Convertir la columna JSON a texto\n",
    "df_results_normalized_csv[\"prediction\"] = df_results_normalized_csv[\"normalized_prediction\"].apply(serialize_info)\n",
    "df_results_normalized_csv = df_results_normalized_csv.drop(columns=[\"normalized_prediction\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce082fbc",
   "metadata": {},
   "source": [
    "### Guardar CSV para subir a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779427df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar en CSV\n",
    "OUTPUT_CSV = os.path.join(CSV_DIR, \"submission.csv\")\n",
    "df_results_normalized_csv.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"Resultados guardados en {OUTPUT_CSV}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_312_CUDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
